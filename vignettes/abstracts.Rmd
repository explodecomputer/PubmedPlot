---
title: "abstracts"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{abstracts}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  eval = FALSE,
  comment = "#>"
)
```

```{r setup}
library(PubmedPlot)
library(jsonlite)
library(dplyr)
library(XML)


term <- '"Mendelian randomisation" [Title] OR "Mendelian randomization" [Title]'

search_url <- "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi"
search_params <- list(
    db = "pubmed",
    term = term,
    retmode = "json",
    usehistory = "y",
    retmax = 20000
)

search_response <- httr::GET(url = search_url, query = search_params)
search_content <- httr::content(search_response, "text")
search_result <- jsonlite::fromJSON(search_content)

pmids <- search_result$esearchresult$idlist

count <- search_result$esearchresult$count %>% as.numeric()
retmax <- search_result$esearchresult$retmax %>% as.numeric()
remainder <- count - retmax

if (remainder > 0) {
    search_params$retstart <- retmax
    search_response <- httr::GET(url = search_url, query = search_params)
    search_content <- httr::content(search_response, "text")
    search_result <- jsonlite::fromJSON(search_content)
    pmids <- c(pmids, search_result$esearchresult$idlist)
}

# length(pmids)

efetch_url <- "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi"




# Prepare the body of the POST request for XML output
efetch_params <- list(
  db = "pubmed",
  id = paste(pmids, collapse = ","),
  rettype = "abstract",
  retmode = "xml"
)

# Query how many pmids

# Make the POST request to fetch abstracts
efetch_response <- httr::POST(url = efetch_url, body = efetch_params, encode = "form")
efetch_content <- httr::content(efetch_response, "text", encoding = "UTF-8")


# Parse the XML content
doc <- XML::xmlParse(efetch_content)
xmltop <- XML::xmlRoot(doc)
# xmlSize(xmltop)
# xmlName(xmltop[[1]][[1]][[1]])
# xmlValue(xmltop[[1]][[]][["PMID"]])

pub_dates <- xpathApply(doc, '//PubmedArticle', \(x) {
    dplyr::tibble(
        pmid = xmlValue(x[[1]][["PMID"]]),
        ab = xmlValue(x[[1]][["Article"]][["Abstract"]]),
        pub_date = lubridate::ymd(
            paste(
                xmlValue(x[["PubmedData"]][["History"]][["PubMedPubDate"]][["Year"]]),
                xmlValue(x[["PubmedData"]][["History"]][["PubMedPubDate"]][["Month"]]),
                xmlValue(x[["PubmedData"]][["History"]][["PubMedPubDate"]][["Day"]])
            )
        ),
        title = xmlValue(x[[1]][["Article"]][["ArticleTitle"]]),
        journal_issn = xmlValue(x[[1]][["Article"]][["Journal"]][["ISSN"]]),
        journal = xmlValue(x[[1]][["Article"]][["Journal"]][["Title"]]),
        author_affil = xmlValue(x[[1]][["Article"]][["AuthorList"]][[1]][["AffiliationInfo"]])
    )
}) %>% bind_rows()

jsonlite::write_json(pub_dates, path="pubmed.json", pretty = TRUE)
```





## Extract tiab

```{r}
term <- '"Mendelian randomisation" [tiab]'

search_url <- "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi"
search_params <- list(
    db = "pubmed",
    term = term,
    retmode = "json",
    usehistory = "y",
    retmax = 20000
)

search_response <- httr::GET(url = search_url, query = search_params)
search_content <- httr::content(search_response, "text")
search_result <- jsonlite::fromJSON(search_content)

pmids2 <- search_result$esearchresult$idlist


term <- '"Mendelian randomization" [tiab]'

search_url <- "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi"
search_params <- list(
    db = "pubmed",
    term = term,
    retmode = "json",
    usehistory = "y",
    retmax = 20000
)

search_response <- httr::GET(url = search_url, query = search_params)
search_content <- httr::content(search_response, "text")
search_result <- jsonlite::fromJSON(search_content)

pmids3 <- search_result$esearchresult$idlist
length(pmids3)

pmidstiab <- unique(c(pmids2, pmids3))
pmids_new <- pmidstiab[!pmidstiab %in% pmids]
length(pmids_new)


efetch_url <- "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi"

# Prepare the body of the POST request for XML output
efetch_params <- list(
  db = "pubmed",
  id = paste(pmids_new, collapse = ","),
  rettype = "abstract",
  retmode = "xml"
)

# Make the POST request to fetch abstracts
efetch_response <- httr::POST(url = efetch_url, body = efetch_params, encode = "form")
efetch_content <- httr::content(efetch_response, "text", encoding = "UTF-8")

# Parse the XML content
doc <- XML::xmlParse(efetch_content)
xmltop <- XML::xmlRoot(doc)
# xmlSize(xmltop)
# xmlName(xmltop[[1]][[1]][[1]])
# xmlValue(xmltop[[1]][[]][["PMID"]])

pub_dates <- xpathApply(doc, '//PubmedArticle', \(x) {
    dplyr::tibble(
        pmid = xmlValue(x[[1]][["PMID"]]),
        ab = xmlValue(x[[1]][["Article"]][["Abstract"]]),
        pub_date = lubridate::ymd(
            paste(
                xmlValue(x[["PubmedData"]][["History"]][["PubMedPubDate"]][["Year"]]),
                xmlValue(x[["PubmedData"]][["History"]][["PubMedPubDate"]][["Month"]]),
                xmlValue(x[["PubmedData"]][["History"]][["PubMedPubDate"]][["Day"]])
            )
        ),
        title = xmlValue(x[[1]][["Article"]][["ArticleTitle"]]),
        journal_issn = xmlValue(x[[1]][["Article"]][["Journal"]][["ISSN"]]),
        journal = xmlValue(x[[1]][["Article"]][["Journal"]][["Title"]]),
        author_affil = xmlValue(x[[1]][["Article"]][["AuthorList"]][[1]][["AffiliationInfo"]])
    )
}) %>% bind_rows()

jsonlite::write_json(pub_dates, path="pubmed_new.json", pretty = TRUE)
```



```{r}
efetch_params <- list(
  db = "pubmed",
  id = "12689998",
  rettype = "abstract",
  retmode = "xml"
)

# Make the POST request to fetch abstracts
efetch_response <- httr::POST(url = efetch_url, body = efetch_params, encode = "form")
efetch_content <- httr::content(efetch_response, "text", encoding = "UTF-8")


```





```{r}
search_term <- function(term) {
  Sys.sleep(1)
  search_url <- "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi"
  search_params <- list(
    db = "pubmed",
    term = term,
    retmode = "json",
    usehistory = "y",
    retmax = 0  # We only want the count and search history, not the IDs
  )

  search_response <- httr::GET(url = search_url, query = search_params)
  search_content <- httr::content(search_response, "text")
  search_result <- jsonlite::fromJSON(search_content)

  # Get the WebEnv, query_key, and count
  web_env <- search_result$esearchresult$webenv
  query_key <- search_result$esearchresult$querykey
  count <- as.numeric(search_result$esearchresult$count)

  cat("Found", count, "articles matching the search term.\n")

  if(count == 0) {
    return(NULL)
  }

  # Step 2: Use EFetch to download records in batches
  fetch_url <- "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi"
  batch_size <- 500  # NCBI recommends no more than 500 records per request
  all_abstracts <- list()

  for (start in seq(0, count - 1, by = batch_size)) {
    cat("Fetching records", start + 1, "to", min(start + batch_size, count), "\n")
    
    fetch_params <- list(
      db = "pubmed",
      query_key = query_key,
      WebEnv = web_env,
      retstart = start,
      retmax = batch_size,
      retmode = "xml",
      rettype = "abstract"
    )
    
    # Add a delay to avoid overloading NCBI servers (3-10 requests per second limit)
    if (start > 0) {
      Sys.sleep(0.5)  # 500ms delay between requests
    }

    fetch_response <- httr::GET(url = fetch_url, query = fetch_params)
    fetch_content <- httr::content(fetch_response, "text", encoding = "UTF-8")

    if (httr::status_code(fetch_response) == 200) {
      doc <- XML::xmlParse(fetch_content)
      xmltop <- XML::xmlRoot(doc)
      # xmlSize(xmltop)
      # xmlName(xmltop[[1]][[1]][[1]])
      # xmlValue(xmltop[[1]][[]][["PMID"]])

      pub_dates <- xpathApply(doc, '//PubmedArticle', \(x) {
        dplyr::tibble(
          pmid = xmlValue(x[[1]][["PMID"]]),
          ab = xmlValue(x[[1]][["Article"]][["Abstract"]]),
          pub_date = lubridate::ymd(
            paste(
              xmlValue(x[["PubmedData"]][["History"]][["PubMedPubDate"]][["Year"]]),
              xmlValue(x[["PubmedData"]][["History"]][["PubMedPubDate"]][["Month"]]),
              xmlValue(x[["PubmedData"]][["History"]][["PubMedPubDate"]][["Day"]])
            )
          ),
          title = xmlValue(x[[1]][["Article"]][["ArticleTitle"]]),
          journal_issn = xmlValue(x[[1]][["Article"]][["Journal"]][["ISSN"]]),
          journal = xmlValue(x[[1]][["Article"]][["Journal"]][["Title"]]),
          author_affil = xmlValue(x[[1]][["Article"]][["AuthorList"]][[1]][["AffiliationInfo"]])
        )
      }) %>% bind_rows()
      all_abstracts[[start+1]] <- pub_dates
    } else {
      cat("Error fetching records:", httr::status_code(fetch_response), "\n")
      cat("Response content:", fetch_content, "\n")
    }
  }
  return(all_abstracts)
}



search_term_by_year <- function(term, years) {
  all_abstracts <- list()
  for (year in years) {
    cat("Searching for year:", year, "\n")
    sterm <- paste0(term, ' AND ("', year, '/01/01"[dp] : "', year, '/12/31"[dp])')
    cat("Search term:", sterm, "\n")
    all_abstracts[[as.character(year)]] <- search_term(sterm)
  }
  all_abstracts <- bind_rows(all_abstracts) %>% filter(!duplicated(pmid))
  return(all_abstracts)
}

all_abstracts <- search_term_by_year('"Mendelian randomization" [tiab]', seq(2003, year(today()), by = 1))


yrs <- seq(2003, year(today()), by = 1)
year_term <- paste0('("Mendelian randomisation" [Title] OR "Mendelian randomization" [Title]) AND ("', yrs, '/01/01"[dp] : "', yrs+1, '/12/31"[dp])')

all_abstracts <- list()
all_abstracts[[1]] <- search_term(year_term[1])

all_abstracts <- sapply(year_term, search_term)

pub_dates_grouped <- group_by_time_interval(all_abstracts)


term <- year_term[1]



```






```{r}





search <- function(term) {
    search_url <- "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi"
    search_params <- list(
        db = "pubmed",
        term = term,
        retmode = "json",
        usehistory = "y",
        retmax = 20000
    )

    search_response <- httr::GET(url = search_url, query = search_params)
    search_content <- httr::content(search_response, "text")
    search_result <- jsonlite::fromJSON(search_content)

    pmids <- search_result$esearchresult$idlist
    # length(pmids)

    summary_url <- "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esummary.fcgi"

    # Prepare the body of the POST request
    # This includes specifying db, id, and retmode as before, but formatted for a POST request
    body_list <- list(
        db = "pubmed",
        id = paste(pmids, collapse = ","),
        retmode = "xml"
    )
    body <- paste(names(body_list), body_list, sep = "=", collapse = "&")

    # Make the POST request
    summary_response <- httr::POST(url = summary_url, body = body, encode = "form")
    summary_content <- httr::content(summary_response, "text", encoding = "UTF-8")

    doc <- XML::xmlParse(summary_content)

    sdoc <- XML::xmlParse(summary_content)
    pubmed_id <- XML::getNodeSet(sdoc, "//Id") %>%
        sapply(., XML::xmlValue)

    pubmed_date_node <- XML::getNodeSet(sdoc, "//Item[@Name='History']/Item[@Name='pubmed']") %>%
        sapply(., \(x) XML::xmlValue(x) %>% strsplit(., " ") %>% {.[[1]][1]})

    pub_dates <- dplyr::tibble(pmid=pubmed_id, pub_date=lubridate::ymd(pubmed_date_node))
    pub_dates
}


search_by_year <- function(term, years) {
  pub_dates <- list()
  for (year in years) {
    cat("Searching for year:", year, "\n")
    sterm <- paste0(term, ' AND ("', year, '/01/01"[dp] : "', year, '/12/31"[dp])')
    cat("Search term:", sterm, "\n")
    pub_dates[[as.character(year)]] <- search_term(sterm)
  }
  pub_dates <- bind_rows(pub_dates) %>% 
    filter(!duplicated(pmid))
  return(pub_dates)
}

a <- search_by_year('"Mendelian randomisation" [Title] OR "Mendelian randomization" [Title]', 2003:2025)
b <- search_by_year('"Mendelian randomisation" [tiab] OR "Mendelian randomization" [tiab]', 2003:2025)

ab <- group_by_time_interval(a)
plot_time_interval(ab)

bb <- group_by_time_interval(b)
plot_time_interval(bb)


ab

ab2 <- group_by_time_interval(all_abstracts)

ab2

all(ab$res$pubmed_date == ab2$res$pubmed_date)

plot(ab$res$n_publications, ab2$res$n_publications)

summary(lm(ab$res$n_publications ~ ab2$res$n_publications))

table(duplicated(ab$pub_dates$pmid))
table(duplicated(ab2$pub_dates$pmid))

subset(b, pub_date > today())
subset(b, pub_date > ymd("2025-01-01"))



a2025 <- search_term('"Mendelian randomisation" [tiab] OR "Mendelian randomization" [tiab] AND ("2025/01/01"[dp] : "2025/12/31"[dp]')

a2025 <- bind_rows(a2025)

a2025$pub_date %>% year() %>% table()


```